# -*- coding: utf-8 -*-
"""CNN Model Final

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1emoWHbJmXj4a5LHnxrIOktr-DR-ulzR7
"""

#import libraries
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import os

#sync to google drive to access dataset
from google.colab import drive
drive.mount('/content/drive')


#load data
X_data = []
y_data = []

folders = [
    ("/content/drive/MyDrive/Datasets_various hospital/Medanta/Non-RD", 0),
    ("/content/drive/MyDrive/Datasets_various hospital/Medanta/RD", 1),
    ("/content/drive/MyDrive/Datasets_various hospital/SMCH/Non-RD", 0),
    ("/content/drive/MyDrive/Datasets_various hospital/SMCH/RD", 1),
    ("/content/drive/MyDrive/Datasets_various hospital/Aravid_eye_care/Non-RD", 0),
    ("/content/drive/MyDrive/Datasets_various hospital/Aravid_eye_care/RD", 1),
    ("/content/drive/MyDrive/Datasets_various hospital/LV_prasad/Non-RD", 0),
    ("/content/drive/MyDrive/Datasets_various hospital/LV_prasad/RD", 1),
]

def load_images(folder_dir, label, max_samples=None):
    count = 0
    for image in os.listdir(folder_dir):
        if max_samples is not None and count >= max_samples:
            break
        full_path = os.path.join(folder_dir, image)
        img = Image.open(full_path)
        img_array = np.array(img)
        X_data.append(img_array)
        y_data.append(label)
        count += 1

max_samples_per_class = min(len(os.listdir(folder_dir)) for folder_dir, label in folders)

for folder_dir, label in folders:
    load_images(folder_dir, label, max_samples=max_samples_per_class)

#resize data
target_size = (256, 256, 3)
X_data = [np.array(Image.fromarray(img).resize(target_size[:-1])) for img in X_data]

#convert data to trainable data type
X_data = np.array(X_data)
y_data = np.array(y_data)

#split data into training and test data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.25)


#create CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(10, activation='relu'),
    Dense(1, activation='sigmoid')
])


#compile model
model.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Plot the accuracy across epochs and train the model
plt.plot(model.fit(
    X_train,
    y_train,
    epochs=20,
).history['accuracy'])
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Distribution of Accuracy Across Epochs')
plt.show()

#import evaluation libraries
from sklearn.metrics import confusion_matrix

y_train_pred_prob = model.predict(X_train)
y_train_pred = (y_train_pred_prob > 0.5).astype(int) #convert predictions to 1 or 0 (yes or no)

# Generate confusion matrix
conf_matrix = confusion_matrix(y_train, y_train_pred)

# Plot confusion matrix using seaborn heatmap
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=['Non-RD', 'RD'], yticklabels=['Non-RD', 'RD'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

#load images from the dataset
n_samples = 5
indices = np.random.choice(len(X_train), n_samples, replace=False)

for i in indices:
    img = X_train[i]
    true_label = "Non-RD" if y_train[i] == 0 else "RD"
    predicted_label = "Non-RD" if y_train_pred[i] == 0 else "RD"

    plt.imshow(img)
    plt.title(f"True Label: {true_label}, Predicted Label: {predicted_label}")
    plt.axis('on')
    plt.show()

from sklearn.metrics import roc_auc_score

true_positives = conf_matrix[1, 1]
false_negatives = conf_matrix[1, 0]
true_negatives = conf_matrix[0, 0]
false_positives = conf_matrix[0, 1]

sensitivity = true_positives / (true_positives + false_negatives)
specificity = true_negatives / (true_negatives + false_positives)

# Calculate AUC-ROC
auc_roc = roc_auc_score(y_train_pred, y_train_pred_prob)

print(f'Sensitivity (True Positive Rate): {sensitivity:.4f}')
print(f'Specificity (True Negative Rate): {specificity:.4f}')
print(f'Area Under the ROC Curve (AUC-ROC): {auc_roc:.4f}')

#find the model's accuracy
eval = model.evaluate(x=X_test, y=y_test)

#import evaluation libraries
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

y_pred_probs = model.predict(X_test).ravel()
y_pred_classes = (y_pred_probs > 0.5).astype(int)  # Convert probabilities to binary predictions
y_test_binary = np.asarray(y_test, dtype=np.int32)

# Evaluate accuracy
accuracy = accuracy_score(y_test_binary, y_pred_classes)
print(f'Accuracy: {accuracy:.4f}')

# Generate classification report
report = classification_report(y_test_binary, y_pred_classes, target_names=['Non-RD', 'RD'])
print('Classification Report:\n', report)

# Calculate error rate
error_rate = 1 - accuracy
print(f'Error Rate: {error_rate:.4f}')

# Generate confusion matrix
conf_matrix = confusion_matrix(y_test_binary, y_pred_classes)

# Plot confusion matrix using seaborn heatmap
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=['Non-RD', 'RD'], yticklabels=['Non-RD', 'RD'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

from sklearn.metrics import roc_auc_score

true_positives = conf_matrix[1, 1]
false_negatives = conf_matrix[1, 0]
true_negatives = conf_matrix[0, 0]
false_positives = conf_matrix[0, 1]

sensitivity = true_positives / (true_positives + false_negatives)
specificity = true_negatives / (true_negatives + false_positives)

# Calculate AUC-ROC
auc_roc = roc_auc_score(y_test_binary, y_pred_probs)

print(f'Sensitivity (True Positive Rate): {sensitivity:.4f}')
print(f'Specificity (True Negative Rate): {specificity:.4f}')
print(f'Area Under the ROC Curve (AUC-ROC): {auc_roc:.4f}')

sensitivity_mean = sensitivity
specificity_mean = specificity
auc_roc_mean = auc_roc

# Standard deviation for sensitivity, specificity, and AUC-ROC
sensitivity_std = np.sqrt(sensitivity * (1 - sensitivity) / (true_positives + false_negatives))
specificity_std = np.sqrt(specificity * (1 - specificity) / (true_negatives + false_positives))
auc_roc_std = 0.5  # AUC-ROC standard deviation for binary classification

# Z-score for a 95% confidence interval
z_score = 1.96

# Calculate confidence intervals
sensitivity_ci = (sensitivity_mean - z_score * sensitivity_std, sensitivity_mean + z_score * sensitivity_std)
specificity_ci = (specificity_mean - z_score * specificity_std, specificity_mean + z_score * specificity_std)

# Print results
print(f'Sensitivity CI: {sensitivity_ci}')
print(f'Specificity CI: {specificity_ci}')

from sklearn.metrics import roc_curve, auc

# finding the area under the curve
fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_probs)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

#loading the images randomly
n_samples = len(X_test)
indices = np.random.choice(len(X_test), n_samples, replace=False)

incorrect_predictions = []

#labelling the images
for i in indices:
    if y_test[i] == 0:
        actual = "Non-RD"
    else:
        actual = "RD"
    if y_pred_classes[i] == 0:
        prediction = "Non-RD"
    else:
        prediction = "RD"

    if y_test[i] != y_pred_classes[i]:
        incorrect_predictions.append((X_test[i], actual, prediction))

# Display all incorrectly predicted images
for img, actual, prediction in incorrect_predictions:
    plt.imshow(img)
    plt.title(f'True: {actual}, Predicted: {prediction}')
    plt.show()

#save model
model.save('FinalMode5.h5')